<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"fengzhiheng.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="本篇博文，主要给大家梳理一下梯度下降算法的发展脉络。">
<meta property="og:type" content="article">
<meta property="og:title" content="梯度下降之我见">
<meta property="og:url" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/index.html">
<meta property="og:site_name" content="Feng Zhiheng&#39;s Blog">
<meta property="og:description" content="本篇博文，主要给大家梳理一下梯度下降算法的发展脉络。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/GL.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/GDUnderstand.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/1.1.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/1.2.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/1.3.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/1.4.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/Nesterov.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/Summary.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/2.1.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/2.2.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/2.3.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/2.4.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/2.5.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/2.6.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/2.7.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/3.1.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/3.2.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/3.3.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/3.4.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/3.5.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/3.6.png">
<meta property="og:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/3.7.png">
<meta property="article:published_time" content="2020-01-22T16:00:00.000Z">
<meta property="article:modified_time" content="2020-01-26T08:54:29.563Z">
<meta property="article:author" content="Feng Zhiheng">
<meta property="article:tag" content="九阴真经">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/GL.png">

<link rel="canonical" href="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>梯度下降之我见 | Feng Zhiheng's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Feng Zhiheng's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://fengzhiheng.github.io/2020/01/23/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B9%8B%E6%88%91%E8%A7%81/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="Feng Zhiheng">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Feng Zhiheng's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          梯度下降之我见
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-01-23 00:00:00" itemprop="dateCreated datePublished" datetime="2020-01-23T00:00:00+08:00">2020-01-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-01-26 16:54:29" itemprop="dateModified" datetime="2020-01-26T16:54:29+08:00">2020-01-26</time>
              </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>本篇博文，主要给大家梳理一下梯度下降算法的发展脉络。<br><a id="more"></a></p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>梯度下降的根是随机梯度下降（SGD）算法，后人在SGD的基础上进行了一系列的发展和改进。改进的思路主要有两个：引入动量和自适应学习率。<br><img src="梯度下降之我见/GL.png" alt="梯度下降法脉络图"></p>
<h2 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h2><h3 id="什么是梯度"><a href="#什么是梯度" class="headerlink" title="什么是梯度"></a>什么是梯度</h3><p><img src="梯度下降之我见/GDUnderstand.png" alt="梯度下降法脉络图"><br>理解梯度之前，我们要理解什么是方向导数；理解方向导数之前，我们需要理解什么是偏导数；理解偏导数之前，我们要对导数有所了解。导数刻画的是函数$f(x)$的变化快慢。偏导数$f_x(x，y)$刻画的是函数$f(x,y)$沿着$x$轴变化的快慢、同理$f_y(x，y)$刻画的是函数$f(x,y)$沿着$y$轴变化的快慢。除了$x$轴、$y$轴之外，如果我们想知道函数沿着方向u的变化快慢怎么办？自然地就引入了方向导数，方向导数刻画的是函数沿着某一个方向变化的快慢。说完方向导数，那什么是梯度呢？梯度就是方向导数最大的那个向量。沿着这个方向，函数变化率最大。<br>一句话概括，梯度下降法是：沿着梯度反方向更新目标函数$𝑓(\theta)$的参数$\theta$，使目标函数取得极小值的过程。换句话说：在参数的梯度方向上更新参数，使得误差逐渐变小！</p>
<h3 id="梯度下降法的三种变体"><a href="#梯度下降法的三种变体" class="headerlink" title="梯度下降法的三种变体"></a>梯度下降法的三种变体</h3><h4 id="Batch-gradient-descent"><a href="#Batch-gradient-descent" class="headerlink" title="Batch gradient descent"></a>Batch gradient descent</h4><p>这种梯度下降法的特点是，遍历整个训练集的数据后更新一次模型参数$\theta$。因此，这种方法收敛的速度非常慢；如果数据集非常大时，这种训练方法是不可接受的，因为对内存来说是一个非常大的挑战；而且，这种方法不能在线训练网络；</p>
<h4 id="Stochastic-gradient-descent"><a href="#Stochastic-gradient-descent" class="headerlink" title="Stochastic gradient descent"></a>Stochastic gradient descent</h4><p>SGD的特点是每来一个数据就更新一次$\theta$，所以导致参数更新过于频繁，而且目标函数波动很大。但是它的优点是，可以在线训练。</p>
<h4 id="Mini-batch-gradient-descent"><a href="#Mini-batch-gradient-descent" class="headerlink" title="Mini-batch gradient descent"></a>Mini-batch gradient descent</h4><p>Mini-batch gradient descent结合了前两者的优点：每次来一个小batch，然后更新一次参数。这样减小了参数更新的方差，使收敛更稳定。值得注意的是：小批量梯度下降法通常也被称为SGD。</p>
<h3 id="梯度下降算法面临的挑战"><a href="#梯度下降算法面临的挑战" class="headerlink" title="梯度下降算法面临的挑战"></a>梯度下降算法面临的挑战</h3><p>第一：如何选择合适的学习率是一个令人头疼的问题<br>    选大了，不好收敛；<br>选小了，收敛太慢；<br>选个固定的，太蠢了，不能根据数据自适应；（利用查表更新学习率，表的构建也是一个问题）<br>第二：如何逃脱鞍点？<br>    鞍点的各个方向的梯度都是零</p>
<h3 id="指数加权平均数"><a href="#指数加权平均数" class="headerlink" title="指数加权平均数"></a>指数加权平均数</h3><p>介绍动量梯度下降算法之前，有必要给大家介绍一下指数加权平均数。<br>指数加权算法的核心在于：它对数据进行加权时不是等权重进行的，而是按照指数权重对所有数据进行了加权。这个权重距离t越近，权重越大，反之也越小。<br>那么，我们为什么要使用加权平均数呢。其实，在训练过程中，数据量是很大的，假设训练样本有100w，即使mini_batch取100，其计算平均值消耗的内存和时间需要的代价都很大，而对于加权平均数，如果β取值0.9那么只需要计算10个数即可计算其平均值，大大节约了内存，计算效率也极大的提高了。</p>
<h3 id="Momentum梯度下降算法"><a href="#Momentum梯度下降算法" class="headerlink" title="Momentum梯度下降算法"></a>Momentum梯度下降算法</h3><p>我们知道，普通的梯度下降算法在更新参数时，只考虑了当前的时刻的梯度。加了动量的梯度下降算法，理解起来很简单，在更新模型参数的时候，不仅只考虑了当前时刻的梯度，过去所有时刻的梯度也都考虑进来了，而且，过去时刻的梯度并不是等权重的，是按照指数加权的。离当前时刻的越近，权重越大。  </p>
<p><img src="梯度下降之我见/1.1.png" alt="梯度下降法脉络图"></p>
<p>换句话说，其实我们引入动量，就像是将一个球从山上推了下来，在下降的过程中的动量也在不断地增加，这个过程和我们更新参数的过程非常类似。<br><img src="梯度下降之我见/1.2.png" alt="梯度下降法脉络图"></p>
<h3 id="Nesterov-Accelerated-Gradient梯度下降算法"><a href="#Nesterov-Accelerated-Gradient梯度下降算法" class="headerlink" title="Nesterov Accelerated Gradient梯度下降算法"></a>Nesterov Accelerated Gradient梯度下降算法</h3><p><img src="梯度下降之我见/1.3.png" alt="梯度下降法脉络图"><br>能不能让我们的球在下降的过程中，有点预测能力？答案当然是可以的，既然，我已经知道，我当前时刻$\theta$的更新量是$\gamma*v_{t-1}$,那我为什么还要用现在这个时刻的梯度，我用下一个时刻的梯度不可以吗？<br><img src="梯度下降之我见/1.4.png" alt="梯度下降法脉络图"><br>观察上图，我们可以看到：蓝色的短矢量代表当前时刻的梯度、蓝色长矢量代表下一时刻的梯度。当使用NAG算法时，我们使用的是下一时刻的梯度，用棕色的矢量表示，加上之前所有时刻的梯度指数加权的结果：红色的矢量，可以得到当前时刻使用NAG算法更新时的结果：绿色矢量。可以发现，用NAG算法，更新一步所走的步长和SGD走两步差不多。<br><img src="梯度下降之我见/Nesterov.png" alt="梯度下降法脉络图"><br>NAG梯段下降算法是俄罗斯的科学家Nesterov最早提出来的。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>SGD看的是现在，加了动量的SGD能够考虑现在和过去；NAG考虑的是下一时刻和过去。<br><img src="梯度下降之我见/Summary.png" alt="梯度下降法脉络图">   </p>
<h2 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h2><p>第一章的落脚点在动量上，第二章节的落脚点就在自适应学习率上。本章主要回答四个问题：AdaGrad和SGD有什么差异，为什么要引入AdaGrad？RMSProp和Adadelta有何异同？Adam结合了什么样的思想，如何结合的？  </p>
<h3 id="AdaGrad和SGD有什么差异，为什么要引入AdaGrad？"><a href="#AdaGrad和SGD有什么差异，为什么要引入AdaGrad？" class="headerlink" title="AdaGrad和SGD有什么差异，为什么要引入AdaGrad？"></a>AdaGrad和SGD有什么差异，为什么要引入AdaGrad？</h3><p>SGD的学习率是固定的，这意味着，在参数更新的过程中，不管当前的情况如何（梯度大，还是梯度小），更新算法获取信息的能力是固定的。显然这是不合理的，我们希望在梯度大的地方，我们能谨慎一些；在梯度小的地方，也就是平坦的地方，我们能大胆一下。要实现这样的功能，我们的学习率能就要根据实际情况进行变化，这就引入了Adagrad。<br><img src="梯度下降之我见/2.1.png" alt="梯度下降法脉络图"><br>如上图所示，Adagrad和SGD的区别在于，Adagrad的学习率是会变的。在梯度大的地方学习率会变小，更新参数时会更谨慎（迈的步子小一些）；在梯度小的地方学习率会变大，更新参数时会更大胆些（迈的步子大一些）；<br>Adagrad的优点是：只需给定一个初始的学习率，之后学习率会自适应地调整。但是也有缺点：在分母位置，每次加的都是正数，所以学习率会越来越小，换句话说就是获取知识的能力变得越来越弱。这就引出了下一个方法Adadelta。</p>
<h3 id="Adadelta与Adagrad有何异同？"><a href="#Adadelta与Adagrad有何异同？" class="headerlink" title="Adadelta与Adagrad有何异同？"></a>Adadelta与Adagrad有何异同？</h3><p>Adadelta主要解决Adagrad中的两个问题：其一单调递减的学习率、其二需要手工选择一个全局的学习率；<br><img src="梯度下降之我见/2.2.png" alt="梯度下降法脉络图"><br>那么如何实现这个想法呢？答案很简单，采用加窗的思想：不是将过去所有的梯度加起来，而是对过去的梯度加了一个时间窗，在窗内的梯度才对我有意义。这样做的好处也很明显了：（1）不像Adagrad那样，梯度会累计到无穷大，而是变成最近梯度的一个局部估计；（2）保证很多次迭代之后，学习率仍然会发生变化（Make Progress）。在实际实现的过程中，使用的正是前文提到的指数加权的形式。<br><img src="梯度下降之我见/2.3.png" alt="梯度下降法脉络图"><br>那么对于Adadelta来说，还有一个问题没有解释清楚：Adadelta如何做到不用初始化一个全局学习率的？关于这部分的详细解释，在<a href="https://arxiv.org/abs/1212.5701" target="_blank" rel="noopener">https://arxiv.org/abs/1212.5701</a> 论文中的第3.2节。我对这一部分的理解是：为什么Adadelta会考虑到这个问题呢？是因为Adadelta的作者发现Adadelta的更新规则和SGD、Momentum相比有些不一样：Adadelta中的学习率是有单位的，而SGD、Momentum是没有单位的，为了使Adadelta也像SGD、Momentum那样：学习率应该是一个无标度的参数。作者把初始化的学习率改成了上一时刻的$\Delta \theta$。用上一个时刻的$\Delta \theta_{t-1}$代替学习率$\eta$。<br>总结一下Adadelta的优点：自适应学习率，而且不用初始化一个全局的学习率。</p>
<h3 id="RMSProp和Adadelta有何异同？"><a href="#RMSProp和Adadelta有何异同？" class="headerlink" title="RMSProp和Adadelta有何异同？"></a>RMSProp和Adadelta有何异同？</h3><p>RMSprop和adagrad的关系：同一时期独立开发的两个算法，都是用来解决Adagrad中学习率大幅度下降的问题。<br><img src="梯度下降之我见/2.4.png" alt="梯度下降法脉络图"><br>上图是RMSprop的更新规则，可以看到RMSprop和Adadelta的第一步是相同的。  </p>
<h3 id="Adam结合了什么样的思想，如何结合的？"><a href="#Adam结合了什么样的思想，如何结合的？" class="headerlink" title="Adam结合了什么样的思想，如何结合的？"></a>Adam结合了什么样的思想，如何结合的？</h3><p>第二章的重头戏是Adam，因为它是连连看的典型产物。之前有人在动量上下功夫，又有人在自适应学习率上下功夫，那么下一步呢？肯定有人会想，能不能把两者结合起来呢？答案当然是可以的，Adam也就是这么做的。<br><img src="梯度下降之我见/2.5.png" alt="梯度下降法脉络图"><br><img src="梯度下降之我见/2.6.png" alt="梯度下降法脉络图"><br><img src="梯度下降之我见/2.7.png" alt="梯度下降法脉络图"><br>上图是Adam的更新规则，可以看到：Adam不仅引入了动量，而且每一步更新时的学习率也是自适应的。</p>
<h2 id="第三章"><a href="#第三章" class="headerlink" title="第三章"></a>第三章</h2><p>第三章的落脚点是针对Adam存在的问题，后人又提出了三种改进的算法。<br><img src="梯度下降之我见/3.1.png" alt="梯度下降法脉络图">   </p>
<h3 id="Adam存在两个比较突出的问题"><a href="#Adam存在两个比较突出的问题" class="headerlink" title="Adam存在两个比较突出的问题"></a>Adam存在两个比较突出的问题</h3><p>第一点：Adams可能不收敛。为什么不收敛，因为Adam阶动量是固定时间窗口内的累积，随着时间窗口的变化，遇到的梯度可能变化特别大，因此会导致震荡不收敛。<br>第二点：Adams会错失全局最优解；有文献[The marginal value of adaptive gradient methods in machine learning]报道，同样的一个优化问题，不同的优化算法可能会找到不同的答案，但自适应学习率的算法（Adam）往往找到非常差的答案。  </p>
<h3 id="Adamax"><a href="#Adamax" class="headerlink" title="Adamax"></a>Adamax</h3><p>Adamax是Adam那篇文献中的一个讨论。文章中提到，能不能把二阶范数改成无穷阶范数呢？因为作者在数学上证明了无穷阶范数也是收敛的。<br><img src="梯度下降之我见/3.2.png" alt="梯度下降法脉络图"><br>从这个角度看，Adamax和Adam唯一的区别就在学习率上。  </p>
<h3 id="Nadam"><a href="#Nadam" class="headerlink" title="Nadam"></a>Nadam</h3><p>介绍Nadam之前，我们需要回顾一下NAG算法。因为，Nadam借鉴了NAG中的思想：不只看眼前，我要看远点，看下一个时刻。NAG中看远点看的是下一时刻的梯度，Dozat对这一点进行了小小个更新，他把NAG的更新规则修改为如下的方式：  <img src="梯度下降之我见/3.3.png" alt="梯度下降法脉络图">   </p>
<p>如何理解呢？可以这样：NAG是用梯度向前看，Dozat想用动量向前看。很自然地，我们就得到了Nadam的更新规则，如公式33所示，把$m_{t-1}$换成了下一时刻的动量$m_t$。<br><img src="梯度下降之我见/3.4.png" alt="梯度下降法脉络图">   </p>
<h3 id="AMSGrad"><a href="#AMSGrad" class="headerlink" title="AMSGrad"></a>AMSGrad</h3><p>AMSGrad和Adam最大的区别在于，AMSGrad用的是过去所有所有$v_{t}$中最大的那个$v_t$，这样就会避免掉入$v_t$不断增长的陷阱中。因$v_t$不断增长会导致学习率不断下降，从而收敛的速度会变得非常慢。<br><img src="梯度下降之我见/3.5.png" alt="梯度下降法脉络图"><br>下图是AMSGrad的更新规则：<br><img src="梯度下降之我见/3.6.png" alt="梯度下降法脉络图"><br>如下图所示，是Adam和AMSGrad收敛速度的比较，可以看到，在作者的实验中，AMSGrad比Adam有着更高的收敛速度和稳定性。<br><img src="梯度下降之我见/3.7.png" alt="梯度下降法脉络图">  </p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上三章，我详细地梳理了梯度下降算法的发展脉络。通过梳理，我发现，连连看的思想无处不在，当人们意识到固定的学习率很糟糕是就会像能不能自适应呢？实现了自适应之后，人们又会想能不能把动量和自适应学习率放在一起呢，于是就有了Adam。后来人们又看了Adam的缺点，能不能让它收敛地更稳健一些呢，于是就有了Adam的各种改进版本。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E4%B9%9D%E9%98%B4%E7%9C%9F%E7%BB%8F/" rel="tag"># 九阴真经</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/01/18/%E5%9B%9E%E4%B9%A1%E5%B0%8F%E6%84%9F/" rel="prev" title="回乡小感">
      <i class="fa fa-chevron-left"></i> 回乡小感
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/01/23/%E6%96%B0%E5%9E%8B%E5%86%A0%E7%8A%B6%E7%97%85%E6%AF%92%E7%9A%84%E8%82%86%E8%99%90/" rel="next" title="新型冠状病毒的肆虐">
      新型冠状病毒的肆虐 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#概述"><span class="nav-number">1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第一章"><span class="nav-number">2.</span> <span class="nav-text">第一章</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#什么是梯度"><span class="nav-number">2.1.</span> <span class="nav-text">什么是梯度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度下降法的三种变体"><span class="nav-number">2.2.</span> <span class="nav-text">梯度下降法的三种变体</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Batch-gradient-descent"><span class="nav-number">2.2.1.</span> <span class="nav-text">Batch gradient descent</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Stochastic-gradient-descent"><span class="nav-number">2.2.2.</span> <span class="nav-text">Stochastic gradient descent</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mini-batch-gradient-descent"><span class="nav-number">2.2.3.</span> <span class="nav-text">Mini-batch gradient descent</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度下降算法面临的挑战"><span class="nav-number">2.3.</span> <span class="nav-text">梯度下降算法面临的挑战</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#指数加权平均数"><span class="nav-number">2.4.</span> <span class="nav-text">指数加权平均数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Momentum梯度下降算法"><span class="nav-number">2.5.</span> <span class="nav-text">Momentum梯度下降算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Nesterov-Accelerated-Gradient梯度下降算法"><span class="nav-number">2.6.</span> <span class="nav-text">Nesterov Accelerated Gradient梯度下降算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#小结"><span class="nav-number">2.7.</span> <span class="nav-text">小结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第二章"><span class="nav-number">3.</span> <span class="nav-text">第二章</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#AdaGrad和SGD有什么差异，为什么要引入AdaGrad？"><span class="nav-number">3.1.</span> <span class="nav-text">AdaGrad和SGD有什么差异，为什么要引入AdaGrad？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adadelta与Adagrad有何异同？"><span class="nav-number">3.2.</span> <span class="nav-text">Adadelta与Adagrad有何异同？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RMSProp和Adadelta有何异同？"><span class="nav-number">3.3.</span> <span class="nav-text">RMSProp和Adadelta有何异同？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adam结合了什么样的思想，如何结合的？"><span class="nav-number">3.4.</span> <span class="nav-text">Adam结合了什么样的思想，如何结合的？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第三章"><span class="nav-number">4.</span> <span class="nav-text">第三章</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Adam存在两个比较突出的问题"><span class="nav-number">4.1.</span> <span class="nav-text">Adam存在两个比较突出的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adamax"><span class="nav-number">4.2.</span> <span class="nav-text">Adamax</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Nadam"><span class="nav-number">4.3.</span> <span class="nav-text">Nadam</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AMSGrad"><span class="nav-number">4.4.</span> <span class="nav-text">AMSGrad</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">5.</span> <span class="nav-text">总结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Feng Zhiheng"
      src="/uploads/avatar.jpg">
  <p class="site-author-name" itemprop="name">Feng Zhiheng</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">89</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Feng Zhiheng</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">154k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">2:20</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '9bad5f6ce5fb909b931c',
      clientSecret: '8af06250d607e8252bf84130a9421a2e5aab692a',
      repo        : 'FengZhiheng.github.io',
      owner       : 'FengZhiheng',
      admin       : ['FengZhiheng'],
      id          : 'c36d71a7973b1806a2f84a9fa5cc0a15',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
